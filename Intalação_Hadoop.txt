1) Instalação VM Ubuntu
	Baixar Iso do Ubuntu Desktop
	Baixar e instalar Oracle VirtualBox
	Configurar a máquina virtual como Linux Ubuntu
	Em armazenamento--> Controladora IDE --> Inserir o ISO do Ubuntu
	Comandos:
	sudo apt-get install build-essential openssh-server vim
	ip addr
	Do terminal externo: ssh 'usuario'@'ipaddress'
	sudo apt install openjdk-8-jdk -y


2) Instalação do Hadoop
	Criar usuário hadoop:  (PULAR ! NÃO CRIAR !)
		su - hdoop
		ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
		cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
		chmod 0600 ~/.ssh/authorized_keys
		ssh localhost
		sair
		ssh localhost
	Intalação (obs: no lugar de hdoop usar o nome do usuário)
		mkdir src
		cd src/
		pwd/home/hdoop/src
		wget -c https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-3.2.2/hadoop-3.2.2.tar.gz
		tar -vxf hadoop-3.2.2.tar.gz
	Configuração:
		cd src/
		pwd/home/hdoop/src
		EDITAR O BASHRC:
		vim .bashrc
			i para iniciar a edição do arquivo
			Enter e inserir texto:
				# Hadoop Related Options
				export HADOOP=/home/hdoop/hadoop
				export HADOOP_INSTALL=$HADOOP_HOME
				export HADOOP_MAPRED_HOME=$HADOOP_HOME
				export HADOOP_COMMON_HOME=$HADOOP_HOME
				export HADOOP_HDFS_HOME=$HADOOP_HOME
				export YARN_HOME=$HADOOP_HOME
				export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
				export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin
				export HADOOP_OPTS"Djava.library.path=$HADOOP_HOME/lib/native
			:wq
		mv src/hadoop-3.2.2 hadoop
		ls -lah

		CRIAR VARIÁVEIS DE AMBIENTE:
		source .bashrc
		env
		INDICAR ONDE ESTÁ O JAVA:
		vim .bashrc
			i para iniciar a edição do arquivo
			export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/
			:wq
		source .bashrc
		echo $JAVA_HOME
		vim hadoop/etc/hadoop/hadoo-env.sh
			i para iniciar a edição do arquivo
			Procurar # Set Hadoop-specific environment variables here
			export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/
			:wq
		CONFIGURAR CORE SITE
		vim hadoop/etc/hadoop/core-site.xml
		i para iniciar a edição do arquivo
		Procurar Put site-specific property
		Digitar:
			<configuration>
			<property>
				<name>hadoop.tmp.dir</name>
				<value>/home/hdoop/tmpdata<value>
			</property>
			<property>
				<name>fs.default.name</name>
				<value>hdfs://127.0.0.1:9000</value>
			</property>
			</configuration>
                :wq
		CONFIGURAR HDFS SITE
		vim hadoop/etc/hadoop/hdfs-site.xml
		i para iniciar a edição do arquivo
		Procurar Put site-specific property
		Digitar:
			<configuration>
			<property>
				<name>dfs.data.dir</name>
				<value>/home/hdoop/dfsdata/namenode<value>
			</property>
			<property>
				<name>dfs.data.dir</name>
				<value>home/hdoop/dfsdata/datanode</value>
			</property>
			<property>
				<name>dfs.replication</name>
				<value>1</value>
			</property>
			</configuration>
		:wq
		CONFIGURAR MAPRED SITE
		vim hadoop/etc/hadoop/mapred-site.xml
		i para iniciar a edição do arquivo
		Procurar Put site-specific property
		Digitar:
			<configuration>
			<property>
				<name>mapreduce.framework.name</name>
				<value>yarn<value>
			</property>
			</configuration>
		:wq
		CONFIGURAR YARN SITE
		vim hadoop/etc/hadoop/yarn-site.xml
		i para iniciar a edição do arquivo
		Procurar Put site-specific property
		Digitar:
			<configuration>
			<property>
				<name>yarn.nodemanager.aux-services</name>
				<value>mapreduce_shuffle<value>
			</property>
			<property>
				<name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
				<value>org.apache.hadoop.mapred.ShuflleHandler<value>
			</property>
			<property>
				<name>yarn.resourcemanager.hostname</name>
				<value>127.0.0.1<value>
			</property>
			<property>
				<name>yarn.acl.enable</name>
				<value>0<value>
			</property>
			<property>
				<name>yarn.nodemanager.env-whitelist</name>
				<value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PERPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<value>
			</property>
			</configuration>
		:wq
		FORMATAR PASTA DE ORGANIZAÇÃO DE NAMENODES
			hdfs namenode -format
		ls hadoop/sbin/start-dfs.sh ^C
		vim .bashrc
			i para iniciar a edição do arquivo
			export PATH=/home/hdoop/hadoop/sbin:$PATH
		:wq
		source .bashrc
		echo $PATH
		INICIAR HADOOP
		start-dfs.sh
		CHECAR SE HADOOP ESTÁ FUNCIONANDO
		jps
		hdfs dfs -mkdir /teste
		hdfs dfs -ls /
		
		
		
		
	
		

